#+title: Research Update
#+options: todo:nil

* Applied Genomics
** Background

- Reworking the Class
- AI ate the quizzes
  - Probably skills that aren't necessary to directly tested on anymore
  - Can focus more on problem solving and applying the knowledge

** Changes Overview

- Got rid of quizzes
- Got rid of 3 presentations for assignments, switched back to individual projects
- Switched to individual assignments instead of group
  # - ensured that everyone had to learn all the skills
- Switched from Sysbio to GitHub codespaces
- Students really liked Galaxy
  # - Until we did the more in-depth ATAC-seq tutorial
- Got rid of Make, and Nextflow and just used Snakemake throughout
  # - Familiarity grew in-between weeks

*** Codespaces

- Common environment with a dev container
  - 1-click and everyone had their own environment
  - No laptop requirements
  - Extensions, the right R version
- Draw back was no HPC experience
  - Ultimately we've had 1 student interested in HPC out of 30
  - Most would be able to use it with the nf-core config or a Snakemake profile
    # and not notice the difference
- Free through GitHub Education!

**** Using Codespaces

[[img:https://docs.github.com/assets/cb-169907/mw-1440/images/help/codespaces/configure-dev-container.webp][Launching a codespace]]

**** Using Codespaces

[[img:https://docs.github.com/assets/cb-80257/mw-1440/images/help/codespaces/configuration-file-choice.webp][Configuring a codespace]]

** Reflections

- There's still value to be gotten with a tighter feedback loop with grading the coding assignments
  # - As opposed to intro bio lab where you have to wait for results, grading, hand the lab reports back...
  # - Maybe ditching GitHub classroom grading, and just writing a small grading script
- Switch environments to pixi
  - Conda/Mamba in GitHub codespaces was a nightmare
- Had a lot of really interesting projects
# I think the concept is a lot of fun to graduate level students
# New skills + an excuse to go on a bit of a lark on whatever you want

* Pixi

** Pixi

[[img:https://pixi.sh/dev/assets/pixi.webp][Pixi Logo]]

** Footguns that are painful for collaboration and Students

*** One way to install it just about everywhere

- Problem: Which way should you install?
  - Anaconda
  - miniconda
  - Mamba
  - Micromamba
  - mambaforge

- Solution:
#+begin_src bash
curl -fsSL https://pixi.sh/install.sh | bash
#+end_src


*** Environment activation is automatic

- Problem: ~conda activate applied-genomics~ the environment in every new terminal
  - The env-name is really the issue

- Solution: Every project has the same commands
    Use the ~pixi shell~ command to open a shell with the environment activated.
    Use the ~pixi shell-hook~ command to print the command to activate the environment in your current shell.
    Use the ~pixi run~ command to run a command in the environment.

*** Tasks built-in
- Problem: ~snakemake --cores 4~

- Solution:
#+begin_src toml
[tasks]
run = "snakemake --cores 4"
upload = { cmd = "rclone sync results/ box:THK_LAB_DATA/results/", depends-on = ["run"] }
#+end_src


*** Storing environment details is taken care of for you

- Problem: ~conda install~ doesn't update the ~environment.yml~
  - Which makes it really hard to reproduce research code as we've learned firsthand...

- Solution ~pixi add~ updates the ~pixi.toml~ for you

*** No built in lock file

- Problem: Versions in the ~environment.yml~ are only half the battle...
# - Going to avoid going off into the weeds here, there is conda-lock

- Solution: ~pixi add~ updates the ~pixi.lock~ file as well behind the scenes

** Set up on a server/locally

#+begin_src bash
curl -fsSL https://pixi.sh/install.sh | bash
# source ~/.bashrc
pixi config append default-channels conda-forge --global
pixi config append default-channels bioconda --global

pixi global install -c bioconda nextflow
pixi g i rclone
#+end_src

** It's gotta be difficult to migrate to, right?

With pixi you can import ~environment.yml~ files into a pixi project. (See import)

#+begin_src bash
pixi init --import environment.yml
#+end_src

This will create a new project with the dependencies from the ~environment.yml~ file.

* TODO Adopt a Code
* Nascent
** Overview

- Benchmarking
- Reproduction of the 2018 Paper
- Comparison of DBNascent results

- Expecting to see ~25% variance
# [cite:@Pints]

** Benchmarking

#+caption: Aligner and Reference improvements
#+name: tbl:1
|          | hg19 | hg38 | CHM13 |
|----------+------+------+-------|
| /        | <>   | <>   | <>    |
| bowtie2  |      |      |       |
| bwa      |      |      |       |
| bwa-mem2 |      |      |       |
| dragmap  |      |      |       |
| HISAT2   |      |      |       |
| STAR     |      |      |       |

- Using the dataset used in =Computational Approaches for Mining GRO-seq Data to Identify and Characterize Active Enhancers=
- Reads aligned
- Transcripts identified
- Potential eRNAs identified
  # I'm gonna have to write a Nextflow workflow for this aren't I? Wait I already did
- Gene and eRNA counts

- Results are ran, just need to find time to dig into them
  # Except for some issues with CHM13 and HISAT2/dragmap

** TODO Reproduction of the 2018 Paper

- bowtie2 => HOMER => Drop the genes(1KB upstream, 10KB downstream) => Select for H3K4me1 and H3K27ac => Potential *eRNAs*
- Three sets of potential eRNAs
  - Kim 2018 (the eRNAs the Peng gave me)
  - hg18 liftOver after HOMER
  - hg19

Notes:
- Just using GM data(So we can release the IMR data later)
- In Pengs case, _hg18_ was used until after homer, and then lift(ed)Over to _hg19_
  - Still not clear at what point that occurred and how much difference the before and after would have

** Reproduction of the 2018 Paper

Goals:
- How many of the potential eRNAs from Peng's set can we recover
- How many of the inducible eRNAs can we recover
- Stretch: Can we identify the inducible eRNAs ourselves

** 2018 Venn Diagram

[[file:eRNAs_overlap.png]]

** Comparison of DBNascent results
*** DBNascent

#+begin_quote
DBNascent is a database of nascent sequencing data created and maintained by the Dowell and Allen Lab at the University of Colorado Boulder.
#+end_quote

HISAT2 => dREG, Tfit

[[https://github.com/Dowell-Lab/DBNascent_Analysis][DBNascent Analysis]]

*** dREG Woes

- DBNascent used HISAT2 and then dREG
  - Tried to build but it's dREG is their own custom software
  - Michael's GPU machines(Free) have CUDA 12

Stuff I tried:

- Building the image by hand.
# Gave up when I got it all built and then dREG threw that it didn't have "Rgtsvm" and saw that was their custom in-house SVM package, and gave up
- A docker image I stumbled on from Cornell's HPC admins
  - only works with CUDA 11
- Adding a "dREG" prep process to Nascent.
# It doesn't work properly with their web portal for submitting bigWigs
- Packaged up Danko's lab pre-dREG pipeline in a Nextflow script and then submitting the bigWigs to their web portal.

Options:
- *Pick up building Rgtsvm and see if it'll even work with CUDA 12*
- Run dREG-nf on all of the samples and then submit them through the web browser.
- Give up and try to compare with homer/groHMM/PINTS
- Find a machine with CUDA 11
